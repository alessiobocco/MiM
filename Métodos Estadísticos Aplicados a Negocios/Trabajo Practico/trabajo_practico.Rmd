---
title: "Trabajo Práctico 1"

author: 
  - Alcantara Fuentes, Victor Alan
  - Bocco, Alessio
  - Buscaglia, Florencia Paula
  - Ojeda, Rodrigo Nicolás
date: '`r format(Sys.time(), "%d %B, %Y")`'
output: 
  bookdown::pdf_document2:
    highlight: pygments
    latex_engine: xelatex
    toc: true
    toc_depth: 2
    fig_width: 4
    fig_height: 3
    fig_cap: yes
    keep_tex: yes
always_allow_html: true
classoption: 12pt
link-citations: true

header-includes:
    - \usepackage{booktabs}
    - \usepackage{colortbl}
    - \usepackage{setspace}
    - \usepackage{lineno}
    - \usepackage{float}
    - \usepackage{caption}
    - \usepackage{chngcntr}
    - \floatstyle{ruled}
    - \newfloat{codechunk}{htbp}{chk}
    - \floatname{codechunk}{Source Code}
    - \floatplacement{figure}{H} #make every figure with caption = h

---

```{r setup, include=FALSE}
library(kableExtra)
library(magrittr)
knitr::opts_chunk$set(tidy="styler")
```

# Introducción

El presente informe corresponde al Trabajo Práctico 1 de Métodos Estadísticos 
Aplicados a los Negocios. El objetivo del mismo es la evaluación del efecto 
de la comunicación entre compradores y vendedores en la plataforma eBay sobre 
las probabilidades de venta. 
El informe se estructura en tres secciones principales y un anexo. La primera consiste en un análisis exploratorio de los datos para la caracterización de las variables y la identificación de _outliers_. Luego, el profiling finaliza con un análisis univariado y bivariado de las variables más pertinentes para el objetivo del estudio. La segunda sección contiene un análisis empírico del efecto de la introducción de nuevas metodologías de comunicación entre oferentes y demandantes. Por último, el reporte concluye con la aplicación de un modelo estadístico para la estimación del efecto de estas nuevas metodologías sobre las ventas. En el anexo se incluyen gráficos accesorios y una copia del código utilizado para la obtención de los resultados mostrados. 

# Exploración del dataset

## Estructura del dataset

El dataset contiene 13 variables cuya descripción se detalla a continuación. 

* date: fecha
* itemid: id del producto
* buyerid: id del comprador
* itemsold: =1 si se vendió el producto, =0 en caso contrario
* message: =1 si el comprador envió un mensaje, =0 en caso contrario
* desktop: =1 si el comprador usó la versión desktop (A), =0 si usó la versión móvil (B) 
* post: =1 a partir del 23 de mayo de 2016, =0 antes de dicha fecha
* category: categoría del producto en venta
* condition: =1 si es nuevo, =0 si es usado
* askingprice: precio ofrecido
* holiday: =1 si es feriado, =0 en caso contrario
* temp: temperatura
* precipitation: precipitaciones


### Tipos de variables

La Tabla \@ref(tab:tipos-variable) muestra los tipos de variables presentes en el dataset. Para cada una de ellas se muestra el tipo de dato y la cantidad de faltantes y valores únicos. 

```{r tipos-variable, echo=FALSE, paged.print=TRUE}
tipos_datos %>%
  dplyr::rename(Variables = variables, Tipo = types, `Faltantes (N)` = missing_count,
                `Faltantes (%)` = missing_percent, `Único (N)` = unique_count, 
                `Único (tasa)` = unique_rate) %>%
  knitr::kable(., "latex", booktabs = T, caption = "Tipos de variables presentes.") %>%
  kableExtra::kable_styling(latex_options = c("striped", "scale_down", "HOLD_position"))
```

Del análisis exploratorio realizado, se observaron las siguientes situaciones:

* Tipos de variables:
  * Fecha: Date
  * Categórica: cateogry
  * Cuantitativas:
    * Continuas: itemid, buyerid, askingprice, temp, precipitation
    * Discretas: itemsold, message, desktop, post, condition, holiday

* Ninguna variable cuenta con valores faltantes.
* Si bien en la Tabla \@ref(tab:tipos-variable) algunas de las variables cuantitativas discretas se muestran como numéricas, en realidad se trata de variables dicotómicas que expresan la ausencia o presencia de determinada cuestión. 

### Variables cuantitativas

Dentro de las variables cuantitativas, la Tabla \@ref(tab:variable-numerica) muestra las principales medidas de resumen que caracterizan a cada una de ellas.

```{r variable-numerica, echo=FALSE, paged.print=TRUE}
diagnostico_variables_numericas %>%
  dplyr::select(-outlier) %>%
  knitr::kable(., "latex", booktabs = T, caption = "Diagnóstico variables cuantitativas") %>%
  kableExtra::kable_styling(latex_options = c("striped", "scale_down", "HOLD_position"))
```

A partir de la Tabla se observa lo siguiente:

* itemdid y buyerid: corresponden a indentificadores unívocos de uso interno y carecen de valor para el presente estudio. 
* Se confirma el carácter dictómico de las variables identificadas en el apartado anterior. 
* La variable askingprice exhibe un fuerte sesgo a izquierda dado que la media es muy superior a la mediana. También tiene una importante disperión dada la diferencia entre el limite superior del intervalo intercuartílico y el máximo. No presenta valores negativos ni nulos por lo que es consistente con su significado. * Las variables meteorológicas _temp_ y _precipitation_ muestran un comportamiento consistente con lo que se esperaría para variables de este tipo. 

### Variables categóricas

La Tabla \@ref(tab:variable-categorica)  muestra una tabla de contigencia con las principales métricas que describen cada categoría de la variable _category_

```{r, variable-categorica, echo=FALSE, paged.print=TRUE}
diagnostico_variables_categoricas %>%
  dplyr::rename(Variable = variables, Clases = levels, Freq = freq, Ratio = ratio, Ranking = rank) %>%
  knitr::kable(., "latex", booktabs = T, caption = "Diagnóstico variables categóricas") %>%
  kableExtra::kable_styling(latex_options = c("striped", "scale_down", "HOLD_position"))
```

Las cinco clases tienen una cantidad de observaciones muy similar, con una frecuencia en torno al 20%. 

### Muestra del dataset 

A continuación de muestra la Tabla \@ref(tab:muestra-dataset) dónde se observan las 5 primeras filas del dataset. 

```{r muestra-dataset, echo=FALSE, paged.print=TRUE}
head(data)  %>%
  knitr::kable(., "latex", booktabs = T, caption = "Muestra del dataset") %>%
  kableExtra::kable_styling(latex_options = c("striped", "scale_down", "HOLD_position"))
```

A partir de éste primer análisis exploratorio y en función del objetivo del estudio se seleccionaron las variables _itemsold_, _desktop_, _post_, _condition_, _holiday_, _temp_ y _precipitation_. Sobre las mencionadas variables se mostrará a continuación un análisis uni y bivariado y se evaluará la presencia de outliers en las variables cuantitativas seleccionadas. 

## Análisis univariado y bivariado

### Cantidad de ventas por plataforma

La Figura \@ref(fig:ventas-plataforma) muestra la cantidad de ventas  por tipo de plataforma. En el panel izquierdo se muestran la cantidad de operaciones totales y en el derecha la cantidad de ventas concretadas. Se observa una distribución bastante pareja entre ambas, con un 45% de las ventas en la versión móvil y un 55% en la versión de escritorio. 

```{r ventas-plataforma, echo = FALSE, fig.align = 'center', fig.cap="Ventas por tipo de plataforma."}
ggpubr::ggarrange(ventas_plataforma, ventas_plataforma_concretadas)
```

### Cantidad de ventas por momento de compra

La Figura \@ref(fig:ventas-momento) muestra la cantidad de operaciones antes y después del 23 de mayo de 2016, momento en que se permitió  interacción entre compradores y vendedores. En el panel izquierdo se muestran la cantidad de operaciones totales y en el derecha la cantidad de ventas concretadas. se observa que la cantidad de operaciones total fue la misma para ambos momentos pero hubo un ligero aumento en las ventas concretadas a partir de la posibilidad de interacción. 

```{r ventas-momento, echo = FALSE, fig.align = 'center', fig.cap="Ventas anteriores y posteriores al cambio en la plataforma."}
ggpubr::ggarrange(ventas_momento, ventas_momento_concretadas)
```

### Cantidad de ventas por condición del producto

La Figura \@ref(fig:ventas-condicion) muestra la cantidad de operaciones (izquierda) y ventas (derecha) según la condición del producto, es decir, si se trata de un producto nuevo o usado. 

```{r ventas-condicion, echo = FALSE, fig.align = 'center', fig.cap="Ventas según la condición del producto."}
ggpubr::ggarrange(condicion_venta, condicion_venta_concretada)
```

### Efecto de las condiciones climáticas

La Figura \@ref(fig:ventas-temperatura) muestra la cantidad de ventas y operaciones por percentil de temperatura. Es decir, se dividió la variable _temp_ en 5 percentiles iguales y se contaron la cantidad de operaciones (izquierda) y ventas (derecha) que se llevaron a cabo en cada uno de ellos. 

```{r ventas-temperatura, echo = FALSE, fig.align = 'center', fig.cap="Ventas según el percentil de temperatura.", fig.width=8}
ggpubr::ggarrange(temperatura_venta, temperatura_venta_concretada)
```

En la Figura no se observan diferencias significativas entre clases tanto para operaciones como para ventas concretadas.

### Precipitación

La Figura \@ref(fig:ventas-precipitacion) muestra la cantidad de ventas y operaciones por tipo de día. La Organización Meteorológica Mundial (OMM) clasifica a los días en lluviosos o secos si la precipitación acumulada diaria es superior a 0.5 mm. Si bien no se conoce la unidad de medida de la variable se asume que está expresada en el sistema métrico. Luego, se contaron la cantidad de operaciones (izquierda) y ventas (derecha) que se llevaron a cabo en cada uno de ellos. 

```{r ventas-precipitacion, echo = FALSE, fig.align = 'center', fig.cap="Ventas según el tipo de día."}
ggpubr::ggarrange(precipitacion_venta, precipitacion_venta_concretada)
```

En la Figura no se observan diferencias significativas entre clases tanto para operaciones como para ventas concretadas.

## Análisis de outliers

Los outliers se identificaron para las variables cuantitativas continuas. La fórmula utilizada para fue la por defecto en R para el diagrama de cajas. La misma se detalla a continuación. 

```{r, eval = FALSE}
# Outliers inferiores
max(min(x), Q1 - (IQR(x)*1.5))
# Outliers superiores
min(max(x), Q3 + (IQR(x)*1.5)) 
```

La Tabla \@ref(tab:out_tabla) muestra los resultados del análisis. Sólo se detectaron valores anómalos en _askingprice_  pero dado que nor formará parte del análisis no se hizo más hincapié en ellos.

```{r out-tabla, echo = FALSE}
diagnostico_outliers %>%
  knitr::kable(., "latex", booktabs = T) %>%
  kableExtra::kable_styling(latex_options = c("striped", "scale_down"))
```

Con respecto a la precipitación, esta variable tiene un comportamiento especial cuando se trata de valores diarios. Existen una gran cantidad de ceros por lo que es muy frecuente la identificación de outliers cuando en realidad no lo son. El análisis de valores extremos de lluvia está fuera del alcance del presente pero se muestra en la Figura \@ref(fig:precip-outlier) la distribución de la variable considerando los valores anómalos en el panel superior y luego de su eliminación en el inferior. 

```{r precip-outlier, echo = FALSE, fig.align = 'center', fig.width=6, fig.height=7, fig.cap="Outliers de la variable precipitación"}
data %>%
  dplyr::select(precipitation) %>%
  dlookr::plot_outlier()
```


# Análisis de ventas

En la presente sección comienza el análisis del impacto en la ventas de la nueva estrategia de comunicación. En la \@ref(fig:intervalo-confianza) muestra la proporción de ventas para las dos plataformas (Escritorio y Móvil) y antes y después de permitir la interacción. El punto de la Figura corresponde a la proporción de ventas en cada combinación de plataforma/momento y las barras al intervalo de confianza del 95% (percentiles).

```{r intervalo-confianza, echo = FALSE, fig.align = 'center', fig.cap="Proporción de las ventas por plataforma y momento de observación."}
intervalos_confianza_plataforma_momento
```

Del gráfico obtenido para los intervalos de confianza se observa la existencia de solapamiento en particular entre la proporción de ventas de la versión Móvil (después del 23.05) y la proporción de ventas de la versión Desktop (antes del 23.05). Tal situación podría generar ruido en la base de datos y no permitir que se pueda diferenciar el real impacto de la variable ‘post’ en el incremento de la probabilidad de que se realice una venta cuando el comprador y vendedor se comuniquen.

Luego de conocer las proporciones con sus respectivos intervalos de confianza se realizó una prueba de proporciones para conocer si el cambio impulsó la cantidad de ventas en la versión Desktop. La \@ref(tab:salida-prueba) muestra los resultados de dicha prueba.

```{r salida-prueba, echo=FALSE, paged.print=TRUE}
prueba_media_tabla %>%
  tibble::as_tibble() %>%
  dplyr::select(`Media estimada` = estimate, Estadístico = statistic,
                p.valor = p.value, método = method, `Hipótesis alternativa` = alternative) %>%
  knitr::kable(., "latex", booktabs = T, caption = "Resúmen de la prueba de hipótesis.") %>%
  kableExtra::kable_styling(latex_options = c("striped", "scale_down", "HOLD_position"))
```

De la prueba de hipótesis realizada se verificó que al 95% de confianza no hay evidencia para rechazar la hipótesis nula de que la proporción de ventas de productos nuevos en la versión Desktop después del 23 de mayo de 2016 no sea superior al 50%, por lo que se puede afirmar que tal proporción no es superior al 50%. 

### Potencia de la prueba

La \@ref(fig:potencia-prueba) muestra la potencia de la prueba anterior para distintos tamaños de muestra utilizando un valor de $\alpha$ de 0.05. 

```{r potencia-prueba, echo = FALSE, fig.align = 'center', fig.cap="Potencia de la prueba de hipótesis para distintos tamaños muestrales.", fig.width=7}
potencia_prueba
```

Se observa el rápido crecimiento de la curva al aumentar el tamaño muestral en sintonía con la que se esperaría en base a la teoría. 

## Modelos de regresión 

En la presente sección se muestran distintos modelos para explicar el efecto de distintas variables sobre la probabilidad de que se concrete una compra. Para ello se utilizará un modelo de probabilidad lineal (LPM, por sus siglas en inglés). Estos modelos son especialmente interesantes para explorar los efectos marginales sobre la variable de interés. A continuación se presentan distintos modelos con un grado creciente de complejidad.

### Modelo básico

La ecuación del modelo básico se muestra en la ecuación  1. Las principales variables del modelo son _desktop_ y _post_. 

```{r model, echo=FALSE,results = "asis"}
equatiomatic::extract_eq(modelo_regresion_basico, intercept = "beta")
```

Los resultados del modelo de muestran en la tabla siguiente.

```{r , echo = FALSE}
modelsummary::modelsummary(modelo_regresion_basico, 
                           vcov = "robust",
                           output = "kableExtra",
                           statistic = c("conf.int",
                           "s.e. = {std.error}", 
                           "t = {statistic}",
                           "p = {p.value}")) 
```

Mientras que el modelo ajustado se muestra en la ecuación 2.

```{r, echo=FALSE}
equatiomatic::extract_eq(modelo_regresion_basico, wrap = TRUE, 
                         use_coefs = TRUE, coef_digits = 3)
```

De la estimación realizada, se observa que, manteniendo lo demás constante, el hecho de utilizar la versión Desktop de la plataforma incrementa la probabilidad de que se realice una venta  en 1.98 puntos porcentuales ($\beta_1$); el hecho de que se esté en un momento a partir del 23.05.2016, incrementa la probabilidad de que se realice una venta en 2.22 puntos porcentuales ($\beta_2$); y el hecho de que se utilice la versión Desktop de la plataforma y a la vez se esté en un momento a partir del 23.05.2016, incrementa la probabilidad de que se realice una venta en 3.58 puntos porcentuales $\beta_3$).
Por otro lado, el hecho que el comprador y vendedor tengan la probabilidad de comunicarse incrementa la probabilidad de que se concrete una venta en 7.79 puntos porcentuales ($\beta_1$ + $\beta_2$ + $\beta_3$).

Además del análisis del modelo básico original se realizaron 1000 replicaciones del mismo para evaluar la estabilidad de los coeficientes. Los resultados del bootstrap se muestra en la Figura \@ref(fig:boot-modelo-basico).

```{r boot-modelo-basico, echo = FALSE, fig.align = 'center', fig.cap="Coeficientes a partir del remuestreo del modelo de regresión básico.", fig.width=7}
histograma_coeficientes_basico
```

En la Figura se muestra la densidad de los coeficientes en negro mientras que las barras rojas corresponden al intervalo de confianza del 95% calculado a partir de los percentiles. 

### Modelo básico + condición del producto

La ecuación del modelo básico se muestra en la ecuación  1. Las principales variables del modelo son _desktop_ y _post_.  La ecuación del modelo se muestra en la ecuación 3. A diferencia del caso anterior, se crean dos dataset filtrando por condición del producto. Es decir, se corre el modelo sobre los productos nuevos y otro modelo sobre los productos usados. 

```{r, echo=FALSE,results = "asis"}
equatiomatic::extract_eq(modelo_regresion_condicion$`Condicion: 1`, intercept = "beta")
```

Los resultados del modelo de muestran en la tabla siguiente.

```{r , echo = FALSE}
model_list <- list(
  "Modelo nuevo" = modelo_regresion_condicion$`Condicion: 1`,
  "Modelo usado" = modelo_regresion_condicion$`Condicion: 0`
)
modelsummary::modelsummary(model_list, 
                           vcov = "robust",
                           output = "kableExtra", 
                           statistic = c("conf.int",
                           "s.e. = {std.error}", 
                           "t = {statistic}",
                           "p = {p.value}")) 
```

La ecuación del modelo ajustado con datos de productos nuevos es:

```{r, echo = FALSE}
equatiomatic::extract_eq(model_list$`Modelo nuevo`, wrap = TRUE, use_coefs = TRUE)
```

La ecuación del modelo ajustado con datos de productos usados es:

```{r, echo = FALSE}
equatiomatic::extract_eq(model_list$`Modelo usado`, wrap = TRUE, use_coefs = TRUE)
```

*Para productos Nuevos:*

De la estimación realizada, se observa que, manteniendo lo demás constante, para productos nuevos el hecho de utilizar la versión Desktop de la plataforma incrementa la probabilidad de que se realice una venta  en 0.48 puntos porcentuales ($\beta_1$); el hecho de que se esté en un momento a partir del 23.05.2016, incrementa la probabilidad de que se realice una venta en 1.56 puntos porcentuales ($\beta_2$); y el hecho de que se utilice la versión Desktop de la plataforma y a la vez se esté en un momento a partir del 23.05.2016, incrementa la probabilidad de que se realice una venta en 4.21 puntos porcentuales Beta 3).
Por otro lado, el hecho que el comprador y vendedor tengan la probabilidad de comunicarse incrementa la probabilidad de que se concrete una venta en 6.26 puntos porcentuales ($\beta_1$ + $\beta_2$ + $\beta_3$).
Comparando con punto anterior (pregunta N° 5), se observa que la estimación, considerando productos nuevos, genera un incremento de probabilidad menor (6.26 vs 7.79) de que se concrete una venta por el hecho de que el comprador y vendedor tengan la probabilidad de comunicarse. Asimismo, en este caso se observa que la variable ‘desktop’ no es estadísticamente significativa.

*Para productos Usados:*

De la estimación realizada, se observa que, manteniendo lo demás constante, para productos usados el hecho de utilizar la versión Desktop de la plataforma incrementa la probabilidad de que se realice una venta  en 2.94 puntos porcentuales ($\beta_1$); el hecho de que se esté en un momento a partir del 23.05.2016, incrementa la probabilidad de que se realice una venta en 2.72 puntos porcentuales ($\beta_2$); y el hecho de que se utilice la versión Desktop de la plataforma y a la vez se esté en un momento a partir del 23.05.2016, incrementa la probabilidad de que se realice una venta en 3.06 puntos porcentuales Beta 3).
Por otro lado, el hecho que el comprador y vendedor tengan la probabilidad de comunicarse incrementa la probabilidad de que se concrete una venta en 8.7 puntos porcentuales ($\beta_1$ + $\beta_2$ + $\beta_3$).
Comparando con punto anterior (pregunta N° 5), se observa que la estimación, considerando productos usados, genera un incremento de probabilidad mayor (8.7 vs 7.79) de que se concrete una venta por el hecho de que el comprador y vendedor tengan la probabilidad de comunicarse. 

Al igual que en el caso anterior se realizó un remuestreo de ambos modelos para conocer la estabilidad de los coeficientes. Los resultados del bootstrap se muestra en la Figura \@ref(fig:boot-modelo-condicion).

```{r boot-modelo-condicion, echo = FALSE, fig.align = 'center', fig.cap="Coeficientes a partir del remuestreo del modelo de regresión discriminando por condición", fig.width=6}
histograma_coeficientes_condicion
```


### Modelo básico + condiciones meteorológicas

La ecuación del modelo es similar al modelo básico pero se incorporan las variables meteorológicas de temperatura y precipitación. Se ha realizado dos tipos de comparaciones. Por un lado se evalúo el modelo climático vs el básico y en una segunda instancia se comparó discriminando la condición del producto mostrada en el apartado anterior. La ecuación del modelo climático se muestra a continuación. 

```{r, echo=FALSE,results = "asis"}
equatiomatic::extract_eq(modelo_regresion_clima, intercept = "beta")
```

Los resultados del modelo de muestran en la tabla siguiente.

```{r , echo = FALSE}
model_list <- list(
  "Modelo básico" = modelo_regresion_basico,
  "Modelo clima" = modelo_regresion_clima
)
modelsummary::modelsummary(model_list, 
                           vcov = "robust",
                           output = "kableExtra",
                           statistic = c("conf.int",
                           "s.e. = {std.error}", 
                           "t = {statistic}",
                           "p = {p.value}")) 
```

Las ecuación del modelo es la siguiente:

```{r, echo = FALSE}
extract_eq(model_list$`Modelo clima`, wrap = TRUE, use_coefs = TRUE)
```

Las estimaciones de los coeficientes cambian sobre todo en el coeficiente de la variable ‘post’ el cual pasa de un $\beta_2$ de 0.022 a 0.015; además las estimaciones finales de la probabilidad de ventas se verían modificadas por el impacto de las variables climáticas, en particular de la variable _temp_ y de la variable _precipitation_. En específico este cambio en las estimaciones se da porque la matriz de variables explicativas ha aumentado la cual sirve de input para calcular los coeficientes individuales. 
Por otro lado, manteniendo lo demás constante, el hecho de que el comprador y vendedor tengan la probabilidad de comunicarse incrementa la probabilidad de que se concrete una venta en 7 puntos porcentuales ($\beta_1$ + $\beta_2$ + $\beta_5$).

Para este modelo también se realizó un boostrap para conocer la estabilidad de los coeficientes. Los resultados se muestran en la Figura \@ref(fig:boot-clima).

```{r boot-clima, echo = FALSE, fig.align = 'center', fig.cap="Coeficientes a partir del remuestreo del modelo de regresión incluyendo variable climáticas", fig.width=6}
histograma_coeficientes_clima
```

La segunda comparación discriminando entre la condición del producto se muestra a continuación. Para el cálculo de los errores se utilizaron para todos los modelos errores robustos dada que no se cumplen los supuestos del modelo lineal. 

```{r , echo = FALSE}
model_list <- list(
  "Modelo básico" = modelo_regresion_basico,
  "Modelo clima" = modelo_regresion_clima,
  "Modelo nuevo" = modelo_regresion_condicion_clima$`Condicion: 1`,
  "Modelo usado" = modelo_regresion_condicion_clima$`Condicion: 0`
)
modelsummary::modelsummary(model_list, 
                           vcov = "robust",
                           output = "kableExtra",
                           statistic = c("conf.int",
                           "s.e. = {std.error}", 
                           "t = {statistic}",
                           "p = {p.value}")) 
```


*Para productos Nuevos:*

Las estimaciones de los coeficientes para el caso de productos nuevos cambian sobre todo en el coeficiente de la variable ‘post’ el cual pasa de un $\beta_2$ de 0.0156 a 0.081; además las estimaciones finales de la probabilidad de ventas se verían modificadas por el impacto de las variables climáticas, en particular de la variable ‘temp’ y de la variable ‘precipitation’. En específico este cambio en las estimaciones se da porque la matriz de variables explicativas ha aumentado la cual sirve de input para calcular los coeficientes individuales. Asimismo, estos cambios se verían impactados porque en este escenario las variables ‘desktop’, ‘post’ y ‘temp’ resultan estadísticamente no significativos.
Por otro lado, manteniendo lo demás constante, el hecho de que el comprador y vendedor tengan la probabilidad de comunicarse incrementa la probabilidad de que se concrete una venta en 7 puntos porcentuales ($\beta_1$ + $\beta_2$ + $\beta_5$).

*Para productos Usados:*

Las estimaciones de los coeficientes para el caso de productos usados cambian sobre todo en el coeficiente de la variable ´post’ el cual pasa de 0.027 a 0.020; además las estimaciones finales de la probabilidad de ventas se verían modificadas por el impacto de las variables climáticas, en particular de la variable ‘temp’ y de la variable ‘precipitation’. En específico este cambio en las estimaciones se da porque la matriz de variables explicativas ha aumentado la cual sirve de input para calcular los coeficientes individuales. Asimismo, estos cambios se verían impactados porque en este escenario la variable ‘temp’ resulta estadísticamente no significativo.
Por otro lado, manteniendo lo demás constante, el hecho de que el comprador y vendedor tengan la probabilidad de comunicarse incrementa la probabilidad de que se concrete una venta en 8 puntos porcentuales ($\beta_1$ + $\beta_2$ + $\beta_5$).

## Bootstrap manual

```{r, echo=TRUE, eval=FALSE}
# ---------------------------------------------------------------------------- #
# Paso 9: Bootstrap manual ----
# ---------------------------------------------------------------------------- #

# Definir semilla
set.seed(1234)

combinaciones <- data %>%
  dplyr::select(desktop, post) %>%
  dplyr::distinct() %>%
  dplyr::arrange(desktop) %>%
  dplyr::mutate(seed = runif(4, min = 1000, max = 9999))

B = 1000 # Cantidad de repeticiones

bootstrap_media_manual <- purrr::map2_dfr(
  .x = combinaciones$desktop,
  .y = combinaciones$post,
  .f = function(aplicacion, momento) {
    
    # Semilla para cada iteracion
    # Se filtran cada una de las combinaciones deseadas
    # de aplicación y momento
    combinaciones %>%
      dplyr::filter(desktop == aplicacion, post == momento) %>%
      dplyr::pull(seed) %>% # Se coloca una semilla para asegurar
                            # la reproducibilidad
      set.seed()
    
    # Seleccion y filtrado de la variable de interes
    ventas <- data %>%
      dplyr::filter(desktop == aplicacion, post == momento) %>%
      dplyr::pull(itemsold) 
    
    results = c() # Vector para guardar resultados
    
    # Dentro del for se iteran B veces seleccionado distintas muestras del 
    # vector de ventas con reposición para asegurar un n constante 
    # sobre cada iteración
    # Luego se calcula la media de cada vector y se guarda en un objeto
    for(b in 1:B){
      # Remuestreo de los datos
      bootSample = sample(ventas, size=length(ventas), replace=TRUE) 
      thetaHat = mean(bootSample) # Calculo de la media de la muestra
      results[b] = thetaHat # Guardar resultados
    }
    
    # Devuelve los resultados con cada media para cada una de las combinaciones
    return(data.frame(desktop = aplicacion, post = momento, media = results))
  } 
)

# Calculo de los intervalos de confianza
bootstrap_intervalos_manual <- bootstrap_media_manual %>%
  # Se agrupan los en función de las combinaciones deseadas
  dplyr::group_by(desktop, post) %>%
  # Se oredenan las medias estimadas en el paso anterior 
  # de menor a mayor para cada uno de los grupos
  dplyr::arrange(media) %>%
  # Sobre los grupos se seleccionan los valores que están 
  # en la vecindad del percentil 2.5 y 97.5, los límites del 
  # intervalo de confianza del 95%
  dplyr::summarise(low.int = map_dbl(round(0.025*B), ~ media[.x]),
                upp.int = map_dbl(round((1 - 0.025)*B), ~ media[.x])) %>%
  # Se desagrupan los resultados
  dplyr::ungroup() %>%
  # Corrección de nombres para visualizar
  dplyr::mutate(desktop = if_else(desktop == 1, 'Desktop', 'Móvil'),
                post = if_else(post == 1, 'Post', 'Pre'))

# Evaluación de los resultados
bootstrap_media_manual %>%
  dplyr::group_by(desktop, post) %>%
  dplyr::summarise(media = mean(media))
```

La salida del bootstrap manual del caso anterior se muestra en la Figura \@ref(fig:boot-manual).

```{r boot-manual, echo = FALSE, fig.align = 'center', fig.cap="Medias e intervalos de confianza a partir del bootstrap manual.", fig.width=6}
bootstrap_intervalos_manual_plot
```


# Código utilizado

A continuación se muestra el código completo para la generación es este reporte. 

```{r, eval=FALSE, tidy=TRUE, tidy.opts=list(width.cutoff=60)}

# ---------------------------------------------------------------------------- #
# Paso 0: Limpieza del espacio de trabajo ----
# ---------------------------------------------------------------------------- #

# Eliminar objetos y limpiar memoria
rm(list = ls()); gc()

# -----------------------------------------------------------------------------

# ---------------------------------------------------------------------------- #
# Paso 1: Cargar paquetes necesarios ----
# ---------------------------------------------------------------------------- #

Sys.setenv(TZ = "UTC")
list.of.packages <- c("dplyr", "magrittr", "ggplot2", "purrr", "magrittr",
                      "lubridate", "tidyr", "readr", "funModeling", "kableExtra",
                      "dlookr", "pwr", "gstools", "equatiomatic", "margins",
                      "rsample")
for (pack in list.of.packages) {
  if (!require(pack, character.only = TRUE)) {
    stop(paste0("Paquete no encontrado: ", pack))
  }
}

options(bitmapType="cairo")

rm(pack); gc()

# -----------------------------------------------------------------------------

# ---------------------------------------------------------------------------- #
# Paso 2: Lectura del dataset ----
# ---------------------------------------------------------------------------- #

data <- readr::read_delim("./data/ebay_data.csv", delim = ';') %>%
  # Corregir formato de fecha 
  dplyr::mutate(date = lubridate::dmy(date)) 

# -----------------------------------------------------------------------------

# ---------------------------------------------------------------------------- #
# Paso 3: Exploración del dataset ----
# ---------------------------------------------------------------------------- #

# Tipos de variables
tipos_datos <- dlookr::diagnose(data)

# Diagnóstico numerico
diagnostico_variables_numericas <- dlookr::diagnose_numeric(data)

# Diagnóstico categorico
diagnostico_variables_categoricas <- dlookr::diagnose_category(data %>%
                                                                 dplyr::select(category), add_date = TRUE)

  
## Análisis univariado

# Cantidad de ventas por plataforma
ventas_plataforma <- ggplot2::ggplot(data = data, ggplot2::aes(x = as.factor(desktop))) +
  ggplot2::geom_bar() +
  ggplot2::theme_bw() +
  ggplot2::xlab("Plataforma") + ggplot2::ylab("Cantidad de operaciones") +
  ggplot2::scale_x_discrete(label = c('Móvil', 'Desktop'))
ventas_plataforma_concretadas <- ggplot2::ggplot(data = data %>%
                                                   dplyr::filter(itemsold == 1),
                                                 ggplot2::aes(x = as.factor(desktop))) +
  ggplot2::geom_bar() +
  ggplot2::theme_bw() +
  ggplot2::xlab("Plataforma") + ggplot2::ylab("Cantidad de ventas") +
  ggplot2::scale_x_discrete(label = c('Móvil', 'Desktop'))


# Cantidad de ventas por momento
ventas_momento <- ggplot2::ggplot(data = data, ggplot2::aes(x = as.factor(post))) +
  ggplot2::geom_bar() +
  ggplot2::theme_bw() +
  ggplot2::xlab("Momento de compra") + ggplot2::ylab("Cantidad de operaciones") +
  ggplot2::scale_x_discrete(label = c('Pre', 'Post'))
ventas_momento_concretadas <- ggplot2::ggplot(data = data %>%
                                                dplyr::filter(itemsold == 1),
                                              ggplot2::aes(x = as.factor(post))) +
  ggplot2::geom_bar() +
  ggplot2::theme_bw() +
  ggplot2::xlab("Momento de compra") + ggplot2::ylab("Cantidad de ventas") +
  ggplot2::scale_x_discrete(label = c('Pre', 'Post'))

# Cantidad de ventas por categoria
ventas_categoria <- ggplot2::ggplot(data = data, ggplot2::aes(x = category)) +
  ggplot2::geom_bar() +
  ggplot2::theme_bw() +
  ggplot2::xlab("Categorías") + ggplot2::ylab("Cantidad de ventas")

# Cantidad de mensajes intercambiados
ventas_mensajes <- ggplot2::ggplot(data = data, ggplot2::aes(x = as.factor(message))) +
  ggplot2::geom_bar() +
  ggplot2::theme_bw() +
  ggplot2::xlab("Mensajes enviados?") + ggplot2::ylab("Cantidad de ventas") +
  ggplot2::scale_x_discrete(label = c('No', 'Si'))

# Cantidad de condicion del producto
condicion_venta <- ggplot2::ggplot(data = data, ggplot2::aes(x = as.factor(condition))) +
  ggplot2::geom_bar() +
  ggplot2::theme_bw() +
  ggplot2::xlab("Condición \ndel producto") + ggplot2::ylab("Cantidad de operaciones") +
  ggplot2::scale_x_discrete(label = c('Usado', 'Nuevo'))
condicion_venta_concretada <- ggplot2::ggplot(data = data %>%
                                                dplyr::filter(itemsold == 1), 
                                              ggplot2::aes(x = as.factor(condition))) +
  ggplot2::geom_bar() +
  ggplot2::theme_bw() +
  ggplot2::xlab("Condición \ndel producto") + ggplot2::ylab("Cantidad de ventas") +
  ggplot2::scale_x_discrete(label = c('Usado', 'Nuevo'))

# Densidad del precio escala natural
densidad_precio <- ggplot2::ggplot(data = data, ggplot2::aes(x = askingprice)) +
  ggplot2::geom_density() +
  ggplot2::geom_rug() +
  ggplot2::xlab("Asking price") + ggplot2::ylab("Densidad") +
  ggplot2::theme_bw()
# Densidad del precio escala log10
densidad_precio_log <-ggplot2::ggplot(data = data, ggplot2::aes(x = askingprice)) +
  ggplot2::geom_density() +
  ggplot2::geom_rug(alpha = 0.2) +
  ggplot2::scale_x_log10() +
  ggplot2::xlab("Asking price") + ggplot2::ylab("Densidad") +
  ggplot2::theme_bw()

## Efecto de las condiciones meteorológicas

# Temperatura 
pctiles <- seq(0, 1, 0.20)

temperatura_venta <- data %>%
  mutate(percentile = gtools::quantcut(temp, q=seq(0, 1, by=0.2)))  %>%
  ggplot2::ggplot(data = ., ggplot2::aes(x = as.factor(percentile))) +
  ggplot2::geom_bar() +
  ggplot2::theme_bw() +
  ggplot2::xlab("Percentil de temperatura") + ggplot2::ylab("Cantidad de operaciones")
temperatura_venta_concretada <- data %>%
  mutate(percentile = gtools::quantcut(temp, q=seq(0, 1, by=0.2)))  %>%
  dplyr::filter(itemsold == 1) %>%
  ggplot2::ggplot(data = ., 
                  ggplot2::aes(x = as.factor(percentile))) +
  ggplot2::geom_bar() +
  ggplot2::theme_bw() +
  ggplot2::xlab("Percentil de temperatura") + ggplot2::ylab("Cantidad de ventas")

# Precipitación
precipitacion_venta <- data %>%
  mutate(dia_lluvioso = if_else(precipitation > 0.5, "Lluvioso", "Seco"))  %>%
  ggplot2::ggplot(data = ., ggplot2::aes(x = as.factor(dia_lluvioso))) +
  ggplot2::geom_bar() +
  ggplot2::theme_bw() +
  ggplot2::xlab("Día lluvioso") + ggplot2::ylab("Cantidad de operaciones")
precipitacion_venta_concretada <- data %>%
  mutate(dia_lluvioso = if_else(precipitation > 0.5, "Lluvioso", "Seco"))  %>%
  dplyr::filter(itemsold == 1) %>%
  ggplot2::ggplot(data = ., ggplot2::aes(x = as.factor(dia_lluvioso))) +
  ggplot2::geom_bar() +
  ggplot2::theme_bw() +
  ggplot2::xlab("Día lluvioso") + ggplot2::ylab("Cantidad de ventas")


# Diagnóstico de outliers
diagnostico_outliers <- dlookr::diagnose_outlier(data %>%
                                                   dplyr::select(askingprice, temp, precipitation))

data %>%
  dplyr::select(askingprice) %>%
  dplyr::mutate(lower.bound = median(askingprice) - 3 * mad(askingprice, constant = 1), # Da valores negativos. Tiene significado? 
                upper.bound = median(askingprice) + 3 * mad(askingprice, constant = 1),
                outlier = if_else(askingprice >= upper.bound | askingprice <= lower.bound, 1, 0)) %>%
  ggplot2::ggplot(data = ., ggplot2::aes(x = askingprice, fill = outlier)) +
  ggplot2::geom_density()

# -----------------------------------------------------------------------------

# ---------------------------------------------------------------------------- #
# Paso 4: Creación de intervalos de confianza ----
# ---------------------------------------------------------------------------- #

# Funcion para el calculo de la media
meanfun <- function(data, i){
  d <- data[i]
  return(mean(d))   
}

# Definir semilla
set.seed(1234)

combinaciones <- data %>%
  dplyr::select(desktop, post) %>%
  dplyr::distinct() %>%
  dplyr::arrange(desktop) %>%
  dplyr::mutate(seed = runif(4, min = 1000, max = 9999))

bootstrap_media <- purrr::map2(
  .x = combinaciones$desktop,
  .y = combinaciones$post,
  .f = function(aplicacion, momento) {
    
    
    # Semilla para cada iteracion
    combinaciones %>%
      dplyr::filter(desktop == aplicacion, post == momento) %>%
      dplyr::pull(seed) %>%
      set.seed()
    
    # Seleccion y filtrado de la variable de interes
    ventas <- data %>%
      dplyr::filter(desktop == aplicacion, post == momento) %>%
      dplyr::pull(itemsold) 
    
    # Remuestreo de la media de ventas
    boot_media <- boot::boot(data = ventas, statistic = meanfun, R = 1000)
    
    # Creacion de variable para nombrar la lista resultante
    nombre_lista <- paste("Desktop:" , aplicacion, "| Post:", momento)
    # Crear objeto para guardar resultados
    resultados <- list(boot_media) 
    # Renombrar objeto resultado
    resultados %<>% purrr::set_names(nombre_lista)
    
  }
) %>% unlist(., recursive = FALSE) # Eliminar un nivel de la lista. 


bootstrap_media_conf <- purrr::map_dfr(
  .x = unique(names(bootstrap_media)),
  .f = function(combinacion) {
    
    boot_media <- bootstrap_media[[combinacion]]
    
    broom::tidy(boot_media, conf.int = T) %>%
      dplyr::mutate(desktop = stringr::str_sub(combinacion, start = 10, end = 10),
                    post = stringr::str_sub(combinacion, start = -1, end = -1)) %>%
      dplyr::select(desktop, post, media = statistic, sesgo = bias, error = std.error,
                    conf.inf = conf.low, conf.sup = conf.high)
    
  }
)

intervalos_confianza_plataforma_momento <- ggplot(data = bootstrap_media_conf, ggplot2::aes(x = desktop, y = media, color = post)) +
  ggplot2::geom_point() +
  ggplot2::scale_x_discrete("Plataforma", labels = c("Móvil", "Escritorio")) +
  ggplot2::scale_color_discrete("Momento", labels = c("Pre", "Post")) +
  ggplot2::geom_errorbar(aes(ymin=conf.inf, ymax=conf.sup), width = .1) +
  ggplot2::theme_bw() +
  ggplot2::xlab("Plataforma") + ggplot2::ylab("Media")
# -----------------------------------------------------------------------------

# ---------------------------------------------------------------------------- #
# Paso 5: Evaluación empírica de ventas + potencia del test ----
# ---------------------------------------------------------------------------- #

ventas <- data %>%
  dplyr::filter(desktop == 1, 
                post == 1,
                condition == 1) %>%
  dplyr::pull(itemsold)

# Test de hipotesis sobre la media
prueba_media <- prop.test(x = sum(ventas), p = 0.5, n = length(ventas),
                          alternative = "greater", correct = FALSE)

prueba_media_tabla <- broom::tidy(prueba_media) 

# Definición de funcion para la creación de secuencias logaritmicas
seq_log <- function(from = 1, to = 100000, by = 1, length.out = log10(to/from)+1) {
  tmp <- exp(seq(log(from), log(to), length.out = length.out))
  tmp[seq(1, length(tmp), by)]  
}

# Definicion de funcion para el calculo de la potencia del test
potencia_prueba_test <- function(null.pi, true.pi, n, alpha = 0.05, alternative = "not equal") { 
  # TO DO: Faltan incluir controles de ejecución
  
  # Seleccion del tipo de prueba a realizar: cola izquierda o derecha 
  # o a dos colas
  # A partir de del tipo de prueba se obtiene el z critico
  z.critico = switch(alternative, "less" = qnorm(alpha), 
                     "greater" = qnorm(1-alpha), qnorm(1-alpha/2)) 
  
  # Calculo del cuantil para el calculo de la probabilidad
  cuantil.una.cola = (z.critico*sqrt(null.pi*(1-null.pi)/n) + null.pi - true.pi) / sqrt(true.pi*(1-true.pi)/n) 
  
  # Corrección para dos colas
  if (alternative == "not equal") {
    z.critico = qnorm(alpha/2)
    # Calculo del cuantil para el calculo de la probabilidad
    cuantil.dos.colas = (z.critico*sqrt(null.pi*(1-null.pi)/n) + null.pi - true.pi) / sqrt(true.pi*(1-true.pi)/n) 
  }
  
  # Calculo de la potencia
  potencia = switch(alternative,
                    "less" = pnorm(cuantil.una.cola),
                    "greater" = 1-pnorm(cuantil.una.cola),
                    pnorm(cuantil.dos.colas) + (1-pnorm(cuantil.una.cola))
  )
  # Devolver potencia
  return(potencia)
}

#potencia_prueba_test(null.pi=0.45, true.pi=c(.5, .6, .8), n= c(10), alternative="greater")


# Evaluar la potencia del test para distintas 
potencia_test <- purrr::map_dfr(
  .x = seq_log(from = 100, to = 100000),
  .f = function(n) {
    
    # Vector de valores de pi
    pistar <- seq(from = 0.5, to=.52, by=0.001)
    
    potencia <- potencia_prueba_test(null.pi = 0.5, true.pi = pistar, n = n,
                      alpha = 0.05, alternative = 'greater')
    
    data.frame(tamano_muestral = factor(n),
               pistar = pistar,
               potencia = potencia)
    
  }
)


potencia_prueba <- ggplot2::ggplot(data = potencia_test, ggplot2::aes(x = pistar, y = potencia, color = tamano_muestral)) +
  ggplot2::geom_line() +
  ggplot2::scale_color_discrete(name = 'Tamaño muestral') +
  ggplot2::theme_bw() +
  ggplot2::xlab(bquote(pi^'*')) + ggplot2::ylab("Potencia")


# Prueba de potencia para una distribucion binomial
#pwr::pwr.p.test(n = 5000, h = 0.5, alternative = "greater")


# -----------------------------------------------------------------------------

# ---------------------------------------------------------------------------- #
# Paso 6: Modelo de regresión lineal básico ----
# ---------------------------------------------------------------------------- #

# Independiente de la condicion del producto

# Formula del modelo lineal
formula_modelo <- formula("itemsold~desktop + post + desktop * post")

# Regresion por MCO
modelo_regresion_basico <- lm(formula_modelo, data = data) 

# Promediode los residuos == 0 
mean(modelo_regresion_basico$residuals)

# Regresion por MCO haciendo bootstrap para conocer la distribución de 
# los coeficientes del modelo

# Semilla para el remuestreo
set.seed(1234) 

# Para el remuestreo se utiliza el paquete rsample. Forma parte de la suite
# de tidyverse y permite utilizar la funcionalidad de los paquetes relacionados

# Se crean N remuestreos del dataset original
# TO DO: Elegir in R lo suficientemente grande, se usa 100 solo para pruebas
bootstrapped_samples_basico <- rsample::bootstraps(data, times = 1000)


# Definición de función para ajustar el modelo lineal
lm_coefs <- function(splits, ...) {
  # se `analysis` para extraer el data frame correspondiente a 
  # cada muestra
  lm(..., data = rsample::analysis(splits)) %>%
    broom::tidy() # tidy permite extraer los coeficientes ajustados 
}

# Se itera sobre cada una de los remuestreos para el ajuste del modelo 
# lineal y la extracción de los coeficientes
bootstrapped_samples_basico$model <- purrr::map(
                          .x = bootstrapped_samples_basico$splits, 
                          .f = lm_coefs, formula_modelo)

# Extraer los coeficientes ajustados para cada muestra y convertir en un 
# data frame para poder graficar
lm_coef_basico <- bootstrapped_samples_basico %>%
  dplyr::select(-splits) %>%
  # Apilar los tibbles en la variable model
  tidyr::unnest(model) %>%
  # Seleccionar las variables de interes
  dplyr::select(id, term, estimate, std.error, statistic,  p.value) %>%
  dplyr::mutate(term = factor(term, levels = c('(Intercept)', 'desktop', 'post', 'desktop:post')))

# Intervalos percentiles
p_ints_basico <- rsample::int_pctl(bootstrapped_samples_basico, model)

histograma_coeficientes_basico <- ggplot2::ggplot(data = lm_coef_basico, ggplot2::aes(x = estimate)) +
  ggplot2::geom_density() +
  ggplot2::facet_wrap(~term, scales = 'free') +
  ggplot2::geom_vline(data = p_ints_basico, aes(xintercept = .lower), col = "red") + 
  ggplot2::geom_vline(data = p_ints_basico, aes(xintercept = .upper), col = "red") + 
  ggplot2::theme_bw() +
  ggplot2::xlab("Coeficiente") + ggplot2::ylab("Cantidad")


relacion_coeficientes <- lm_coef_basico %>%
  dplyr::select(id, term, estimate) %>%
  # Put different parameters in columns
  tidyr::spread(term, estimate) %>% 
  # Keep only numeric columns
  dplyr::select(-id) %>%
  GGally::ggscatmat(alpha = .25) +
  ggplot2::theme_bw() +
  ggplot2::xlab("Valor del estimador (eje x)") +
  ggplot2::ylab("Valor del estimador (eje y)")

# -----------------------------------------------------------------------------

# ---------------------------------------------------------------------------- #
# Paso 7: Modelo de regresión lineal por condicion de producto ----
# ---------------------------------------------------------------------------- #

# Formula del modelo lineal
formula_modelo_condicion <- formula("itemsold~desktop + post + desktop * post")

# Discriminando entre producto nuevo y usado
modelo_regresion_condicion <- purrr::map(
  .x = unique(data$condition),
  .f = function(condicion) {
    
    # Filtrar datos por condicion
    data_condicion <- data %>%
      dplyr::filter(condition == condicion)
    
    modelo_regresion <- lm(formula_modelo_condicion, data = data_condicion) 
    
    #broom::tidy(modelo_regresion) %>%
    #  dplyr::mutate(signif = p.value < 0.05,
    #    condition = condicion)
    
    # Creacion de variable para nombrar la lista resultante
    nombre_lista <- paste("Condicion:" , condicion)
    # Crear objeto para guardar resultados
    resultados <- list(modelo_regresion) 
    # Renombrar objeto resultado
    resultados %<>% purrr::set_names(nombre_lista)
    
  }
) %>% unlist(., recursive = FALSE) # Eliminar un nivel de la lista. 

# Remuestreo de coeficientes discriminando entre producto nuevo y usado
bootstrap_model_condition <- purrr::map_dfr(
  .x = unique(data$condition),
  .f = function(condicion) {
    
    set.seed(condicion)
    bt_resamples <-  rsample::bootstraps(data %>%
                                 dplyr::filter(condition == condicion), times = 1000)
    
    bt_resamples$model <- purrr::map(.x = bt_resamples$splits, 
                              .f = lm_coefs, 
                              formula_modelo_condicion)
    
    lm_coef <- 
      bt_resamples %>%
      dplyr::select(-splits) %>%
      # Turn it into a tibble by stacking the `models` col
      unnest() %>%
      dplyr::mutate(condition = condicion) %>%
      # Get rid of unneeded columns
      dplyr::select(id, condition, term, estimate, std.error, statistic,  p.value) 
    
  }
)

histograma_coeficientes_condicion <- ggplot2::ggplot(data = bootstrap_model_condition, 
                                           ggplot2::aes(x = estimate, fill = as.factor(condition))) +
  ggplot2::geom_density(alpha = 0.4) +
  ggplot2::scale_fill_discrete(name = 'Condición') +
  ggplot2::facet_wrap(.~term, scales = 'free') +
  ggplot2::theme_bw() +
  ggplot2::xlab("Coeficiente") + ggplot2::ylab("Cantidad obs.") +
  ggplot2::theme(legend.position = 'bottom')


bootstrap_model_condition %>%
  dplyr::group_by(condition, term) %>%
  dplyr::summarise(estimate = mean(estimate))

# -----------------------------------------------------------------------------

# ---------------------------------------------------------------------------- #
# Paso 8: Modelo de regresión lineal con condiciones climaticas ----
# ---------------------------------------------------------------------------- #

# Incorporacion de variables climáticas

# Formula del modelo lineal
formula_modelo_clima <- formula("itemsold~desktop + post + desktop * post + precipitation + temp")

# Regresion por MCO
modelo_regresion_clima <- lm(formula_modelo_clima, data = data) 

# Se crean N remuestreos del dataset original
# TO DO: Elegir in R lo suficientemente grande, se usa 100 solo para pruebas
bootstrapped_samples_clima <- rsample::bootstraps(data, times = 1000)


# Se itera sobre cada una de los remuestreos para el ajuste del modelo 
# lineal y la extracción de los coeficientes
bootstrapped_samples_clima$model <- purrr::map(.x = bootstrapped_samples_clima$splits, 
                                         .f = lm_coefs, formula_modelo_clima)

# Extraer los coeficientes ajustados para cada muestra y convertir en un 
# data frame para poder graficar
lm_coef_clima <- bootstrapped_samples_clima %>%
  dplyr::select(-splits) %>%
  # Apilar los tibbles en la variable model
  tidyr::unnest(model) %>%
  # Seleccionar las variables de interes
  dplyr::select(id, term, estimate, std.error, statistic,  p.value) %>%
  dplyr::mutate(term = factor(term, levels = c('(Intercept)', 'desktop', 'post', 'desktop:post', "temp", 'precipitation')))


histograma_coeficientes_clima <- ggplot2::ggplot(data = lm_coef_clima, 
                                                     ggplot2::aes(x = estimate)) +
  ggplot2::geom_density(alpha = 0.4) +
  ggplot2::scale_fill_discrete(name = 'Condición') +
  ggplot2::facet_wrap(.~term, scales = 'free') +
  ggplot2::theme_bw() +
  ggplot2::xlab("Coeficiente") + ggplot2::ylab("Cantidad obs.") +
  ggplot2::theme(legend.position = 'bottom')



# Discriminando entre producto nuevo y usado
modelo_regresion_condicion_clima <- purrr::map(
  .x = unique(data$condition),
  .f = function(condicion) {
    
    # Filtrar datos por condicion
    data_condicion <- data %>%
      dplyr::filter(condition == condicion)
    
    modelo_regresion <- lm(formula_modelo_clima, data = data_condicion) 
    
    #broom::tidy(modelo_regresion) %>%
    #  dplyr::mutate(signif = p.value < 0.05,
    #                condition = condicion)
    
    # Creacion de variable para nombrar la lista resultante
    nombre_lista <- paste("Condicion:" , condicion)
    # Crear objeto para guardar resultados
    resultados <- list(modelo_regresion) 
    # Renombrar objeto resultado
    resultados %<>% purrr::set_names(nombre_lista)
    
  }
) %>% unlist(., recursive = FALSE) # Eliminar un nivel de la lista. 
# ----------------------------------------------------------------------------

# ---------------------------------------------------------------------------- #
# Paso 9: Bootstrap manual ----
# ---------------------------------------------------------------------------- #

# Definir semilla
set.seed(1234)

combinaciones <- data %>%
  dplyr::select(desktop, post) %>%
  dplyr::distinct() %>%
  dplyr::arrange(desktop) %>%
  dplyr::mutate(seed = runif(4, min = 1000, max = 9999))

B = 1000 # Cantidad de repeticiones

bootstrap_media_manual <- purrr::map2_dfr(
  .x = combinaciones$desktop,
  .y = combinaciones$post,
  .f = function(aplicacion, momento) {
    
    # Semilla para cada iteracion
    # Se filtran cada una de las combinaciones deseadas
    # de aplicación y momento
    combinaciones %>%
      dplyr::filter(desktop == aplicacion, post == momento) %>%
      dplyr::pull(seed) %>% # Se coloca una semilla para asegurar
                            # la reproducibilidad
      set.seed()
    
    # Seleccion y filtrado de la variable de interes
    ventas <- data %>%
      dplyr::filter(desktop == aplicacion, post == momento) %>%
      dplyr::pull(itemsold) 
    
    results = c() # Vector para guardar resultados
    
    # Dentro del for se iteran B veces seleccionado distintas muestras del 
    # vector de ventas con reposición para asegurar un n constante 
    # sobre cada iteración
    # Luego se calcula la media de cada vector y se guarda en un objeto
    for(b in 1:B){
      bootSample = sample(ventas, size=length(ventas), replace=TRUE) # Remuestreo de los datos
      thetaHat = mean(bootSample) # Calculo de la media de la muestra
      results[b] = thetaHat # Guardar resultados
    }
    
    # Devuelve los resultados con cada media para cada una de las combinaciones
    return(data.frame(desktop = aplicacion, post = momento, media = results))
  } 
)

# Calculo de los intervalos de confianza
bootstrap_intervalos_manual <- bootstrap_media_manual %>%
  # Se agrupan los en función de las combinaciones deseadas
  dplyr::group_by(desktop, post) %>%
  # Se oredenan las medias estimadas en el paso anterior 
  # de menor a mayor para cada uno de los grupos
  dplyr::arrange(media) %>%
  # Sobre los grupos se seleccionan los valores que están 
  # en la vecindad del percentil 2.5 y 97.5, los límites del 
  # intervalo de confianza del 95%
  dplyr::summarise(low.int = map_dbl(round(0.025*B), ~ media[.x]),
                upp.int = map_dbl(round((1 - 0.025)*B), ~ media[.x])) %>%
  # Se desagrupan los resultados
  dplyr::ungroup() %>%
  # Corrección de nombres para visualizar
  dplyr::mutate(desktop = if_else(desktop == 1, 'Desktop', 'Móvil'),
                post = if_else(post == 1, 'Post', 'Pre'))

# Evaluación de los resultados
bootstrap_media_manual %>%
  dplyr::group_by(desktop, post) %>%
  dplyr::summarise(media = mean(media))


bootstrap_intervalos_manual_plot <- ggplot(data = bootstrap_media_manual %>%
                                             dplyr::mutate(desktop = if_else(desktop == 1, 'Desktop', 'Móvil'),
                                                           post = if_else(post == 1, 'Post', 'Pre')), ggplot2::aes(x = media)) +
  ggplot2::geom_density() +
  ggplot2::facet_wrap(desktop~post, scales = 'free') +
  ggplot2::geom_vline(data = bootstrap_intervalos_manual, ggplot2::aes(xintercept = low.int), color = 'red') +
  ggplot2::geom_vline(data = bootstrap_intervalos_manual, ggplot2::aes(xintercept = upp.int), color = 'red') +
  
  ggplot2::theme_bw() +
  ggplot2::ylab("Media")
# ----------------------------------------------------------------------------

# ---------------------------------------------------------------------------- #
# ---- Paso n: Generar reporte ----
# ---------------------------------------------------------------------------- #

# Generar informe en PDF

output.dir <- getwd()
rmarkdown::render(
  input = "./trabajo_practico.Rmd",
  output_file = "trabajo_practico.pdf",
  output_dir = output.dir
)

# -----------------------------------------------------------------------------


```

